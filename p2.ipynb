{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('F:/Workspace/dataset1/LinearX.csv',index_col=False,header=None)\n",
    "train.columns=['X', 'Y']\n",
    "label=pd.read_csv('F:/Workspace/dataset1/LinearY.csv',index_col=False,header=None)\n",
    "label.columns=['Label']\n",
    "full=pd.concat([train,label],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.357887</td>\n",
       "      <td>1.114346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.599734</td>\n",
       "      <td>0.910270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.118251</td>\n",
       "      <td>1.007064</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.253931</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.744856</td>\n",
       "      <td>-0.964423</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.322591</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0.964615</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.348820</td>\n",
       "      <td>-2.904418</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.384484</td>\n",
       "      <td>-1.400062</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.641800</td>\n",
       "      <td>0.971140</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-3.231615</td>\n",
       "      <td>0.578323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.728023</td>\n",
       "      <td>-0.721204</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.758275</td>\n",
       "      <td>-1.950257</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.523439</td>\n",
       "      <td>-1.164556</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.789385</td>\n",
       "      <td>1.134588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.003383</td>\n",
       "      <td>1.129986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.271639</td>\n",
       "      <td>1.075872</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.085561</td>\n",
       "      <td>0.766634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.477299</td>\n",
       "      <td>1.296691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.134526</td>\n",
       "      <td>-0.893413</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2.118173</td>\n",
       "      <td>1.028562</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.980459</td>\n",
       "      <td>1.224970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.136320</td>\n",
       "      <td>1.134085</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.273592</td>\n",
       "      <td>0.817214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.398179</td>\n",
       "      <td>1.234951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.521657</td>\n",
       "      <td>1.372829</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.906039</td>\n",
       "      <td>-1.922132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.342564</td>\n",
       "      <td>0.625157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-2.499572</td>\n",
       "      <td>1.012112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.642635</td>\n",
       "      <td>0.732758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>-1.445341</td>\n",
       "      <td>0.600709</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>-0.630119</td>\n",
       "      <td>0.832922</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>-1.068788</td>\n",
       "      <td>1.066609</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>-0.967422</td>\n",
       "      <td>0.831455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-0.030637</td>\n",
       "      <td>1.346532</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-0.400189</td>\n",
       "      <td>1.004700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>-1.015711</td>\n",
       "      <td>-2.537885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.073253</td>\n",
       "      <td>0.668715</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>-1.511700</td>\n",
       "      <td>-0.069632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-1.349185</td>\n",
       "      <td>-2.854431</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>-2.162085</td>\n",
       "      <td>0.876750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>-0.757611</td>\n",
       "      <td>-2.044177</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>-0.862119</td>\n",
       "      <td>0.990242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>-1.590013</td>\n",
       "      <td>-2.396298</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>-0.231957</td>\n",
       "      <td>-0.511655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-0.466106</td>\n",
       "      <td>-1.957663</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>-0.804585</td>\n",
       "      <td>-2.454807</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>-0.986367</td>\n",
       "      <td>-1.888206</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>-1.691201</td>\n",
       "      <td>1.112450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>-0.864354</td>\n",
       "      <td>1.157269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>-2.558854</td>\n",
       "      <td>-0.893441</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>-1.120874</td>\n",
       "      <td>-0.034711</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-1.316108</td>\n",
       "      <td>0.964134</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>-3.152979</td>\n",
       "      <td>-1.652346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-0.139143</td>\n",
       "      <td>0.280039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.598968</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-2.289717</td>\n",
       "      <td>-3.242433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-2.646294</td>\n",
       "      <td>-1.484602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-2.284485</td>\n",
       "      <td>-1.602472</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.256392</td>\n",
       "      <td>0.072847</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X         Y  Label\n",
       "0   -0.357887  1.114346    0.0\n",
       "1   -0.599734  0.910270    0.0\n",
       "2   -2.118251  1.007064    0.0\n",
       "3   -1.253931  0.818353    0.0\n",
       "4   -0.744856 -0.964423    1.0\n",
       "5   -1.322591  0.960905    0.0\n",
       "6   -0.342475  0.964615    0.0\n",
       "7   -1.348820 -2.904418    1.0\n",
       "8   -1.384484 -1.400062    1.0\n",
       "9   -0.641800  0.971140    0.0\n",
       "10  -3.231615  0.578323    0.0\n",
       "11  -0.728023 -0.721204    1.0\n",
       "12  -1.758275 -1.950257    1.0\n",
       "13  -0.523439 -1.164556    1.0\n",
       "14  -0.789385  1.134588    0.0\n",
       "15  -2.003383  1.129986    0.0\n",
       "16  -1.271639  1.075872    0.0\n",
       "17  -1.085561  0.766634    0.0\n",
       "18  -1.477299  1.296691    0.0\n",
       "19  -1.134526 -0.893413    1.0\n",
       "20  -2.118173  1.028562    0.0\n",
       "21  -0.980459  1.224970    0.0\n",
       "22   0.136320  1.134085    0.0\n",
       "23   0.273592  0.817214    0.0\n",
       "24  -0.398179  1.234951    0.0\n",
       "25  -0.521657  1.372829    0.0\n",
       "26  -1.906039 -1.922132    1.0\n",
       "27   0.342564  0.625157    1.0\n",
       "28  -2.499572  1.012112    0.0\n",
       "29  -0.642635  0.732758    0.0\n",
       "..        ...       ...    ...\n",
       "470 -1.445341  0.600709    0.0\n",
       "471 -0.630119  0.832922    0.0\n",
       "472 -1.068788  1.066609    0.0\n",
       "473 -0.967422  0.831455    0.0\n",
       "474 -0.030637  1.346532    0.0\n",
       "475 -0.400189  1.004700    0.0\n",
       "476 -1.015711 -2.537885    1.0\n",
       "477  0.073253  0.668715    0.0\n",
       "478 -1.511700 -0.069632    1.0\n",
       "479 -1.349185 -2.854431    1.0\n",
       "480 -2.162085  0.876750    0.0\n",
       "481 -0.757611 -2.044177    1.0\n",
       "482 -0.862119  0.990242    0.0\n",
       "483 -1.590013 -2.396298    1.0\n",
       "484 -0.231957 -0.511655    1.0\n",
       "485 -0.466106 -1.957663    1.0\n",
       "486 -0.804585 -2.454807    1.0\n",
       "487 -0.986367 -1.888206    1.0\n",
       "488 -1.691201  1.112450    0.0\n",
       "489 -0.864354  1.157269    0.0\n",
       "490 -2.558854 -0.893441    1.0\n",
       "491 -1.120874 -0.034711    1.0\n",
       "492 -1.316108  0.964134    0.0\n",
       "493 -3.152979 -1.652346    1.0\n",
       "494 -0.139143  0.280039    1.0\n",
       "495 -0.408782  0.598968    0.0\n",
       "496 -2.289717 -3.242433    1.0\n",
       "497 -2.646294 -1.484602    1.0\n",
       "498 -2.284485 -1.602472    1.0\n",
       "499  0.256392  0.072847    1.0\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, NNodes, activate, deltaActivate):\n",
    "        self.NNodes = NNodes # the number of nodes in the hidden layer\n",
    "        self.activate = activate # a function used to activate\n",
    "        self.deltaActivate = deltaActivate # the derivative of activate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, X, Y, learningRate, epochs, regLambda):\n",
    "        \"\"\"\n",
    "        This function is used to train the model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy matrix\n",
    "            The matrix containing sample features for training.\n",
    "        Y : numpy array\n",
    "            The array containing sample labels for training.\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        W1\n",
    "        b1\n",
    "        W2\n",
    "        b2\n",
    "        # Initialize your weight matrices first.\n",
    "        # (hint: check the sizes of your weight matrices first!)\n",
    "        \n",
    "        \n",
    "        # For each epoch, do\n",
    "            # For each training sample (X[i], Y[i]), do\n",
    "                # 1. Forward propagate once. Use the function \"forward\" here!\n",
    "        \n",
    "                \n",
    "                # 2. Backward progate once. Use the function \"backpropagate\" here!\n",
    "                \n",
    "                \n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the labels for each sample in X.\n",
    "        Parameters\n",
    "        X : numpy matrix\n",
    "            The matrix containing sample features for testing.\n",
    "        Returns\n",
    "        -------\n",
    "        YPredict : numpy array\n",
    "            The predictions of X.\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        return YPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, X):\n",
    "        # Perform matrix multiplication and activation twice (one for each layer).\n",
    "        # (hint: add a bias term before multiplication)\n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "    def backpropagate(self):\n",
    "        # Compute loss / cost using the getCost function.\n",
    "                \n",
    "                \n",
    "                \n",
    "        # Compute gradient for each layer.\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Update weight matrices.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "    def getCost(self, YTrue, YPredict):\n",
    "        # Compute loss / cost in terms of crossentropy.\n",
    "        # (hint: your regularization term should appear here)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dataDir):\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy matrix\n",
    "        Input data samples.\n",
    "    Y : numpy array\n",
    "        Input data labels.\n",
    "    '''\n",
    "    # TO-DO for this part:\n",
    "    # Use your preferred method to read the csv files.\n",
    "    # Write your codes here:\n",
    "    \n",
    "    \n",
    "    # Hint: use print(X.shape) to check if your results are valid.\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, Y, K = 5):\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "    result : List[[train, test]]\n",
    "        \"train\" is a list of indices corresponding to the training samples in the data.\n",
    "        \"test\" is a list of indices corresponding to the testing samples in the data.\n",
    "        For example, if the first list in the result is [[0, 1, 2, 3], [4]], then the 4th\n",
    "        sample in the data is used for testing while the 0th, 1st, 2nd, and 3rd samples\n",
    "        are for training.\n",
    "    '''\n",
    "    \n",
    "    # Make sure you shuffle each train list.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDecisionBoundary(model, X, Y):\n",
    "    \"\"\"\n",
    "    Plot the decision boundary given by model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : model, whose parameters are used to plot the decision boundary.\n",
    "    X : input data\n",
    "    Y : input labels\n",
    "    \"\"\"\n",
    "    x1_array, x2_array = np.meshgrid(np.arange(-4, 4, 0.01), np.arange(-4, 4, 0.01))\n",
    "    grid_coordinates = np.c_[x1_array.ravel(), x2_array.ravel()]\n",
    "    Z = model.predict(grid_coordinates)\n",
    "    Z = Z.reshape(x1_array.shape)\n",
    "    plt.contourf(x1_array, x2_array, Z, cmap=plt.cm.bwr)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.bwr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(XTrain, YTrain, args):\n",
    "    \"\"\"\n",
    "    This function is used for the training phase.\n",
    "    Parameters\n",
    "    ----------\n",
    "    XTrain : numpy matrix\n",
    "        The matrix containing samples features (not indices) for training.\n",
    "    YTrain : numpy array\n",
    "        The array containing labels for training.\n",
    "    args : List\n",
    "        The list of parameters to set up the NN model.\n",
    "    Returns\n",
    "    -------\n",
    "    NN : NeuralNetwork object\n",
    "        This should be the trained NN object.\n",
    "    \"\"\"\n",
    "    # 1. Initializes a network object with given args.\n",
    "    \n",
    "    \n",
    "    # 2. Train the model with the function \"fit\".\n",
    "    # (hint: use the plotDecisionBoundary function to visualize after training)\n",
    "    \n",
    "    \n",
    "    # 3. Return the model.\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(XTest, model):\n",
    "    \"\"\"\n",
    "    This function is used for the testing phase.\n",
    "    Parameters\n",
    "    ----------\n",
    "    XTest : numpy matrix\n",
    "        The matrix containing samples features (not indices) for testing.\n",
    "    model : NeuralNetwork object\n",
    "        This should be a trained NN model.\n",
    "    Returns\n",
    "    -------\n",
    "    YPredict : numpy array\n",
    "        The predictions of X.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(YTrue, YPredict):\n",
    "    \"\"\"\n",
    "    Computes the confusion matrix.\n",
    "    Parameters\n",
    "    ----------\n",
    "    YTrue : numpy array\n",
    "        This array contains the ground truth.\n",
    "    YPredict : numpy array\n",
    "        This array contains the predictions.\n",
    "    Returns\n",
    "    CM : numpy matrix\n",
    "        The confusion matrix.\n",
    "    \"\"\"\n",
    "    pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerformanceScores(YTrue, YPredict):\n",
    "    \"\"\"\n",
    "    Computes the accuracy, precision, recall, f1 score.\n",
    "    Parameters\n",
    "    ----------\n",
    "    YTrue : numpy array\n",
    "        This array contains the ground truth.\n",
    "    YPredict : numpy array\n",
    "        This array contains the predictions.\n",
    "    Returns\n",
    "    {\"CM\" : numpy matrix,\n",
    "    \"accuracy\" : float,\n",
    "    \"precision\" : float,\n",
    "    \"recall\" : float,\n",
    "    \"f1\" : float}\n",
    "        This should be a dictionary.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
